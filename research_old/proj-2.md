---
layout: post
title: 'Interpretable Machine Learning'
---

My thesis research is on algorithms for interpreting machine-learned data representations, particularly in the context of Diffusion Maps embeddings of quantum molecular dynamics simulations. The core idea of this research is that, by comparing the gradients of the low-dimensional learned representation with gradients of a predefined set of 'interpretable' functions, we can statistically establish an interpretation for the behavior of black-box learned data representations.

{% include image.html url="https://arxiv.org/abs/1811.11891" image="projects/proj-2/manifoldlasso.png" %}
